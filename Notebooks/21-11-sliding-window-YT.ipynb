{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/tensorflow/lib/python3.5/site-packages/skvideo/__init__.py:356: UserWarning: avconv/avprobe not found in path: \n",
      "  warnings.warn(\"avconv/avprobe not found in path: \" + str(path), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import skvideo.io\n",
    "import skvideo.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Nadam, Adam\n",
    "from keras.utils import np_utils, generic_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/tensorflow/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image specification + Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows,img_cols,img_depth=120,160,15\n",
    "r_state = 42\n",
    "np.random.seed(r_state)\n",
    "tf.set_random_seed(r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 120, 160, 15) (0, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "train_nb, test_nb = 196, 100\n",
    "x_train = np.zeros((0,img_rows,img_cols,img_depth)).astype('float32')# variable to store entire dataset\n",
    "x_test = np.zeros((0,img_rows,img_cols,img_depth)).astype('float32')\n",
    "# fr_arr = fr_arr.astype('float32')\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFrames(vdata,start,end,width,step): # width of the window and step\n",
    "    x_arr = np.zeros((0,img_rows,img_cols,img_depth))\n",
    "    \n",
    "    frame_number = 0\n",
    "    uniq_frames_nb = end - start  # + width - (end - start) % width\n",
    "    uniq_frames_nb = uniq_frames_nb - (uniq_frames_nb - width) % step\n",
    "    print('uniq frames: ', uniq_frames_nb,start,end)\n",
    "    frames = []\n",
    "    \n",
    "    for frame in vdata:\n",
    "#         print('fr_nb:', frame_number,'out of:', start + uniq_frames_nb)\n",
    "        if (frame_number >= start and frame_number < start + uniq_frames_nb):\n",
    "#             print('i\\'m inside')\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            res_img = cv2.resize(frame, (img_cols, img_rows), interpolation=cv2.INTER_AREA)\n",
    "            frames.append(res_img)\n",
    "        if frame_number > start + uniq_frames_nb:\n",
    "            frame_number = 0\n",
    "            break\n",
    "        frame_number += 1\n",
    "    print('real frames: ', len(frames))\n",
    "        \n",
    "    # sliding window itself\n",
    "    nb_x = (uniq_frames_nb - width) / step + 1\n",
    "    print('adding',nb_x,'windows')\n",
    "    for i in range(int(nb_x)):\n",
    "        fr_arr = np.zeros((img_depth,img_rows,img_cols))\n",
    "        fr_arr = fr_arr.astype('float32')\n",
    "#         print(fr_arr.shape, img_depth, len(frames), ((int(nb_x) - 1) * step + img_depth - 1))\n",
    "        \n",
    "        for j in range(img_depth):\n",
    "            fr_arr[j] = frames[i * step + j]\n",
    "        fr_arr = np.rollaxis(fr_arr,0,3)\n",
    "        fr_arr = np.expand_dims(fr_arr, axis = 0)\n",
    "        x_arr = np.concatenate((x_arr, fr_arr), axis=0) \n",
    "        \n",
    "    return x_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFrames(fr_arr, v_name, v_ext, acc, border=1000000, start_bias=0):\n",
    "    fr_numbers = open(v_name + '.csv', 'r')\n",
    "    st_len = fr_arr.shape[0]\n",
    "    \n",
    "    for line in fr_numbers:\n",
    "        line = line.split(',')\n",
    "        print(line)\n",
    "        videodata = skvideo.io.vreader(v_name + v_ext)\n",
    "        if int(line[2]) == acc: # int(line[1])\n",
    "            print('class: ', acc)\n",
    "            fr_arr = np.concatenate((fr_arr,readFrames(videodata,int(line[0]) + start_bias,int(line[1]),img_depth,5)), axis = 0)\n",
    "        if fr_arr.shape[0] > border:\n",
    "            break\n",
    "    \n",
    "    print('done:', fr_arr.shape)\n",
    "    return fr_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load YouTube videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = loadFrames(x_test, '/home/misha/Documents/Thesis/Dataset/BNG_white_1', '.mov', 1,start_bias=-20)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = loadFrames(x_test, '/home/misha/Documents/Thesis/Dataset/BNG_white_1', '.mov', 0, border=158)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test[0:158]\n",
    "nb_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.zeros(158)\n",
    "y_test[0:79] = 1\n",
    "y_test[79:] = 0\n",
    "print(y_test.shape)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '577', '0\\n']\n",
      "class:  0\n",
      "uniq frames:  575 0 577\n",
      "real frames:  575\n",
      "adding 113.0 windows\n",
      "done: (113, 120, 160, 15)\n",
      "(113, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "filename = 'small_dataset/0-0'\n",
    "x_train = loadFrames(x_train, filename, '.mp4', 0)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['450', '1250', '0\\n']\n",
      "class:  0\n",
      "uniq frames:  800 450 1250\n",
      "real frames:  800\n",
      "adding 158.0 windows\n",
      "['1290', '1983', '0\\n']\n",
      "class:  0\n",
      "uniq frames:  690 1290 1983\n",
      "real frames:  690\n",
      "adding 136.0 windows\n",
      "['2350', '2536', '0\\n']\n",
      "class:  0\n",
      "uniq frames:  185 2350 2536\n",
      "real frames:  185\n",
      "adding 35.0 windows\n",
      "['2570', '3040', '0\\n']\n",
      "class:  0\n",
      "uniq frames:  470 2570 3040\n",
      "real frames:  470\n",
      "adding 92.0 windows\n",
      "['3075', '3640', '0\\n']\n",
      "class:  0\n",
      "uniq frames:  565 3075 3640\n",
      "real frames:  565\n",
      "adding 111.0 windows\n",
      "done: (645, 120, 160, 15)\n",
      "(645, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "filename = 'small_dataset/0 4K camera example for Traffic Monitoring (Road, Interchage) [360p]'\n",
    "x_train = loadFrames(x_train, filename, '.mp4', 0)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '740', '0\\n']\n",
      "class:  0\n",
      "uniq frames:  740 0 740\n",
      "real frames:  740\n",
      "adding 146.0 windows\n",
      "done: (791, 120, 160, 15)\n",
      "(791, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "filename = 'small_dataset/0 36th St & Wetmore Ave - Double Stop Sign Run In Front Of Cross Traffic 2017-02-27 [360p]'\n",
    "x_train = loadFrames(x_train, filename, '.mp4', 0)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '400', '0\\n']\n",
      "class:  0\n",
      "uniq frames:  400 0 400\n",
      "real frames:  400\n",
      "adding 78.0 windows\n",
      "done: (869, 120, 160, 15)\n",
      "(869, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "filename = 'small_dataset/0 36th St & Wetmore Ave - Everett PD Vehicle Nearly Rolls Through Stop 2017-02-27 [360p]'\n",
    "x_train = loadFrames(x_train, filename, '.mp4', 0)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '600', '0\\n']\n",
      "class:  0\n",
      "uniq frames:  600 0 600\n",
      "real frames:  600\n",
      "adding 118.0 windows\n",
      "done: (987, 120, 160, 15)\n",
      "(987, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "filename = 'small_dataset/0 Full HD Car megapixel CCTV camera Video Demo [360p]'\n",
    "x_train = loadFrames(x_train, filename, '.mp4', 0)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['250', '328', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  75 250 328\n",
      "real frames:  75\n",
      "adding 13.0 windows\n",
      "['329', '495', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  165 329 495\n",
      "real frames:  165\n",
      "adding 31.0 windows\n",
      "['560', '728', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  165 560 728\n",
      "real frames:  165\n",
      "adding 31.0 windows\n",
      "['840', '1020', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  180 840 1020\n",
      "real frames:  180\n",
      "adding 34.0 windows\n",
      "['1250', '1423', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  170 1250 1423\n",
      "real frames:  170\n",
      "adding 32.0 windows\n",
      "['1485', '1730', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  245 1485 1730\n",
      "real frames:  245\n",
      "adding 47.0 windows\n",
      "['1835', '2280', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  445 1835 2280\n",
      "real frames:  445\n",
      "adding 87.0 windows\n",
      "['2505', '2685', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  180 2505 2685\n",
      "real frames:  180\n",
      "adding 34.0 windows\n",
      "['2740', '2970', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  230 2740 2970\n",
      "real frames:  230\n",
      "adding 44.0 windows\n",
      "['2990', '3240', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  250 2990 3240\n",
      "real frames:  250\n",
      "adding 48.0 windows\n",
      "['3300', '3600', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  300 3300 3600\n",
      "real frames:  300\n",
      "adding 58.0 windows\n",
      "['3630', '3685', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  55 3630 3685\n",
      "real frames:  55\n",
      "adding 9.0 windows\n",
      "['3686', '3835', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  145 3686 3835\n",
      "real frames:  145\n",
      "adding 27.0 windows\n",
      "['3840', '4100', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  260 3840 4100\n",
      "real frames:  260\n",
      "adding 50.0 windows\n",
      "['4160', '4510', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  350 4160 4510\n",
      "real frames:  350\n",
      "adding 68.0 windows\n",
      "['4535', '4750', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  215 4535 4750\n",
      "real frames:  215\n",
      "adding 41.0 windows\n",
      "['5335', '5570', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  235 5335 5570\n",
      "real frames:  235\n",
      "adding 45.0 windows\n",
      "['5640', '5805', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  165 5640 5805\n",
      "real frames:  165\n",
      "adding 31.0 windows\n",
      "['5815', '5970', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  155 5815 5970\n",
      "real frames:  155\n",
      "adding 29.0 windows\n",
      "['6085', '6340', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  255 6085 6340\n",
      "real frames:  255\n",
      "adding 49.0 windows\n",
      "done: (808, 120, 160, 15)\n",
      "(1795, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "filename = 'small_dataset/1 BeamNG.drive - CCTV Crash Compilation #3 [360p]'\n",
    "x_train_temp = np.zeros((0,img_rows,img_cols,img_depth))\n",
    "x_train_temp = loadFrames(x_train_temp, filename, '.mp4', 1, border=x_train.shape[0])\n",
    "x_train = np.concatenate((x_train, x_train_temp), axis=0) \n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['155', '365', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  210 155 365\n",
      "real frames:  210\n",
      "adding 40.0 windows\n",
      "['480', '625', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  145 480 625\n",
      "real frames:  145\n",
      "adding 27.0 windows\n",
      "['690', '850', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  160 690 850\n",
      "real frames:  160\n",
      "adding 30.0 windows\n",
      "['902', '1030', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  125 902 1030\n",
      "real frames:  125\n",
      "adding 23.0 windows\n",
      "['1225', '1425', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  200 1225 1425\n",
      "real frames:  200\n",
      "adding 38.0 windows\n",
      "['1615', '1850', '1\\n']\n",
      "class:  1\n",
      "uniq frames:  235 1615 1850\n",
      "real frames:  235\n",
      "adding 45.0 windows\n",
      "done: (203, 120, 160, 15)\n",
      "(1998, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "filename = 'small_dataset/1 Highest Quality CCTV Crashes On The Web [360p]'\n",
    "\n",
    "x_train_temp = np.zeros((0,img_rows,img_cols,img_depth))\n",
    "x_train_temp = loadFrames(x_train_temp, filename, '.mp4', 1, border=200)\n",
    "x_train = np.concatenate((x_train, x_train_temp), axis=0) \n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape) # 987, 2422 = 1974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1974, 120, 160, 15)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[0:1974]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_to_viz = x_train[50]\n",
    "# vid_to_viz = np.flip(np.squeeze(X_val_new[5], axis=3),1)\n",
    "vid_to_viz = np.rollaxis(vid_to_viz, 2, 0)\n",
    "_, axes = plt.subplots(ncols=5,nrows=3,figsize=(15,7))\n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        axes[i][j].axis('off')\n",
    "        axes[i][j].set_title(i * 5 + j)\n",
    "        axes[i][j].imshow(vid_to_viz[i * 5 + j],cmap = 'gray')\n",
    "                   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid_to_viz = x_train_0[3]\n",
    "# vid_to_viz = np.flip(np.squeeze(X_val_new[5], axis=3),1)\n",
    "# vid_to_viz = np.rollaxis(vid_to_viz, 2, 0)\n",
    "# _, axes = plt.subplots(ncols=5,nrows=3,figsize=(15,7))\n",
    "# for i in range(3):\n",
    "#     for j in range(5):\n",
    "#         axes[i][j].axis('off')\n",
    "#         axes[i][j].set_title(i * 5 + j)\n",
    "#         axes[i][j].imshow(vid_to_viz[i * 5 + j],cmap = 'gray')\n",
    "                   \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 120, 160, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.expand_dims(x_test, axis=4)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "# x_test, y_test = shuffle(x_test,y_test, random_state = r_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading accident class training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Image resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all frames classes (takes long time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1974, 120, 160, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=4)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign label to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1974,)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.ones((x_train.shape[0],),dtype=int)\n",
    "y_train[0:987] = 0\n",
    "y_train[987:] = 1\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "nb_classes = 2 \n",
    "nb_epoch = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### convert class vectors to binary class matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1974, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle train data\n",
    "# x_train, y_train = shuffle(x_train,y_train, random_state = r_state)\n",
    "\n",
    "x_train, y_train = shuffle(x_train,y_train, random_state = r_state)\n",
    "\n",
    "# x_train = np.expand_dims(x_train, axis=4)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = shuffle(x_test, y_test, random_state = r_state)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### number of convolutional filters to use at each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters = [32, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### level of pooling to perform at each layer (POOL x POOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pool = [2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Level of convolution to perform at each layer (CONV x CONV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_conv = [3,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "# train_set -= np.mean(train_set)\n",
    "x_train /=np.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_rows, img_cols, img_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.astype('float32')\n",
    "x_test /= np.max(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_initializer=\"normal\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution3D(16, (4, 4, 1),\n",
    "input_shape=(img_rows, img_cols, img_depth, 1), activation='relu'))\n",
    "\n",
    "# model.add(Convolution3D(16, (3, 3, 2), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(nb_pool[0], nb_pool[0], nb_pool[0])))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution3D(32, (4, 4, 4), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Convolution3D(64, (3, 3, 2), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Convolution3D(128, (3, 3, 1), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 1)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, init='normal', activation='relu'))\n",
    "model.add(Dense(256, init='normal', activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(nb_classes,init='normal'))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model.optimizer.lr.assign(0.1)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Nadam(lr=0.0005))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 117, 157, 15, 16)  272       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 58, 78, 7, 16)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 58, 78, 7, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 55, 75, 4, 32)     32800     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 27, 37, 2, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 27, 37, 2, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 25, 35, 1, 64)     36928     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25, 35, 1, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 12, 17, 1, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 17, 1, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 13056)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1671296   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,774,834\n",
      "Trainable params: 1,774,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.flip(x_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1579, 120, 160, 15, 1) (395, 120, 160, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.flip(x_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x_train, x_test, y_train, y_test =  train_test_split(x_train, y_train, test_size=0.2, random_state=r_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new = np.expand_dims(X_train_new, axis=4)\n",
    "# print(X_train_new.shape)\n",
    "\n",
    "# X_val_new = np.expand_dims(X_val_new, axis=4)\n",
    "# print(X_val_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "nb_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1579 samples, validate on 395 samples\n",
      "Epoch 1/2\n",
      "1579/1579 [==============================] - 17s - loss: 0.4166 - acc: 0.8018 - val_loss: 0.1162 - val_acc: 0.9949\n",
      "Epoch 2/2\n",
      "1579/1579 [==============================] - 15s - loss: 0.0540 - acc: 0.9867 - val_loss: 0.0228 - val_acc: 0.9975\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, validation_data=(x_test,y_test),\n",
    "          batch_size=batch_size, epochs=nb_epoch, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_new = np.flip(X_val_new, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_new = np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend(['train_loss','val_loss','train_acc', 'val_acc'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss=hist.history['loss']\n",
    "# val_loss=hist.history['val_loss']\n",
    "# train_acc=hist.history['acc']\n",
    "# val_acc=hist.history['val_acc']\n",
    "# xc=range(10)\n",
    "\n",
    "# plt.figure(1,figsize=(7,5))\n",
    "# plt.plot(xc,train_loss)\n",
    "# plt.plot(xc,val_loss)\n",
    "# plt.xlabel('num of Epochs')\n",
    "# plt.ylabel('loss')\n",
    "# plt.title('train_loss vs val_loss')\n",
    "# plt.grid(True)\n",
    "# plt.legend(['train','val'])\n",
    "# print(plt.style.available) # use bmh, classic,ggplot for big pictures\n",
    "# plt.style.use(['classic'])\n",
    "\n",
    "# plt.figure(2,figsize=(7,5))\n",
    "# plt.plot(xc,train_acc)\n",
    "# plt.plot(xc,val_acc)\n",
    "# plt.xlabel('num of Epochs')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.title('train_acc vs val_acc')\n",
    "# plt.grid(True)\n",
    "# plt.legend(['train','val'],loc=4)\n",
    "# #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "# plt.style.use(['classic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
